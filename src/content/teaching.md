+++
title = "Teaching"
id = "teaching"
comments = false
schematype = "CollectionPage"
banner = "//studio-70.org/wp-content/uploads/cohort-learning-e1518296152746-1.jpg"
+++

{{< figure src="https://studio-70.org/wp-content/uploads/cohort-learning-e1518296152746-1.jpg"
class="old_photo" >}}

Here I will put all the material I use for teaching.
For now, it is just a list of useful links!

## Technical tools

- [Guide](/post/remote_editing) to how to develop on remote hosts
- Very easy [introduction](/post/git_intro) to git
- A fully [interactive tutorial](https://learngitbranching.js.org/?locale=it_IT) about git
- When git is a [mess](http://justinhileman.info/article/git-pretty/)
- If you need a review of any technology, check [this](https://learnxinyminutes.com)

## Machine Learning

- A good university course on [Machine Learning](https://www.youtube.com/playlist?list=PLUenpfvlyoa0rMoE5nXA8kdctBKE9eSob)
- A good university course on [Probabilistic Graphical Models](https://ermongroup.github.io/cs228-notes/) (including Bayesian Networks, Markov Random Fields, and Conditional Random Fields)

## Neural Networks

- The [_deep learning book_](https://www.deeplearningbook.org/). A must.
- An awesome explanation of [backpropagation](https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c)
- A tool to visualize [how nn learn](http://www.emergentmind.com/neural-network) (check input and output)
- Another tool to study [how and what nn are learning](https://playground.tensorflow.org)
- Resources to understand convolutions and transposed convolutions: [vdumoulin](https://github.com/vdumoulin/conv_arithmetic), [ezyang](https://ezyang.github.io/convolution-visualizer/index.html)
- A nice paper to understand [LSTM networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- Understanding [update algorithms](https://ruder.io/optimizing-gradient-descent/index.html)
  [Attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) and [transformers](https://jalammar.github.io/illustrated-transformer/) explained visually
